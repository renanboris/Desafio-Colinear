# üìä Accounting Dataset Generator

Ferramenta de Engenharia de Dados desenvolvida para processar, limpar e padronizar arquivos cont√°beis brutos (CSV) visando o treinamento de modelos de Machine Learning.

## üöÄ Como executar

1. **Pr√©-requisitos**
- Certifique-se de ter o Python instalado. Instale as depend√™ncias:
```bash
   pip install pandas
```

- Estrutura de Pastas Coloque os arquivos CSV brutos dentro de uma pasta chamada input/ na raiz do projeto.

*Plaintext*

/
‚îú‚îÄ‚îÄ input/
‚îÇ   ‚îú‚îÄ‚îÄ lancamentos_11.csv
‚îÇ   ‚îú‚îÄ‚îÄ lancamentos_106.csv
‚îÇ   ‚îî‚îÄ‚îÄ lancamentos_109.csv
‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îú‚îÄ‚îÄ parser.py
‚îÇ   ‚îî‚îÄ‚îÄ text_cleaning_tool.py
‚îî‚îÄ‚îÄ main.py

*Execu√ß√£o - Rode o script principal:*

```bash
python main.py
```

*Resultado O arquivo consolidado dataset_final.csv ser√° gerado na raiz do projeto.*

## üõ†Ô∏è O que o projeto faz

- Input: L√™ m√∫ltiplos arquivos CSV cont√°beis com layouts hier√°rquicos (Pai: Conta -> Filho: Lan√ßamentos).

- Parsing Inteligente:

- Detecta automaticamente a posi√ß√£o das colunas (Data, Hist√≥rico, D√©bito, Cr√©dito).

- Associa cada lan√ßamento √† sua conta cont√°bil pai correspondente.

- Sanitiza√ß√£o (Limpeza):

- Remove acentos, pontua√ß√£o e stopwords (ex: "de", "para").

- Converte tudo para min√∫sculo.

- Formata valores num√©ricos e define tipo D√©bito (d) ou Cr√©dito (c).

*Consolida√ß√£o: Gera um dataset √∫nico, sem informa√ß√µes duplicadas e formatado conforme a regra de neg√≥cio: [descri√ß√£o limpa] valor [0.00] [d/c]*

## üß† Decis√µes T√©cnicas

Biblioteca CSV ou Pandas na leitura: Optei por usar a biblioteca nativa csv para o parsing linha-a-linha.

*Motivo:* Os arquivos originais possuem estrutura hier√°rquica (cabe√ßalhos de conta intercalados com dados) que dificultaria o uso direto do *pd.read_csv*.

*Detec√ß√£o Din√¢mica de Colunas:* O script varre o cabe√ßalho procurando por palavras-chave ("Hist√≥rico", "D√©bito"). Isso torna o c√≥digo resiliente a mudan√ßas de layout.

*Pandas no Final:* Utilizado apenas na etapa de consolida√ß√£o para garantir a estrutura do CSV final e remover duplicatas de forma perform√°tica.

*Arquitetura Modular:* Separa√ß√£o clara de responsabilidades:

*main.py:* Orquestrador.
*services/parser.py:* L√≥gica de extra√ß√£o.
*services/text_cleaning_tool.py:* Regras de Limpeza.

## ‚ö†Ô∏è Dificuldades Superadas

*Encoding e Caracteres Especiais:* Arquivos com codifica√ß√£o e muita sujeira quebravam a leitura inicial. Resolvido com tratamento de erros (replace) e encoding correto.

*Varia√ß√£o de Layout:* Arquivos onde a coluna "Hist√≥rico" poderia mudar de posi√ß√£o. Resolvido com a l√≥gica de header_found e busca por √≠ndices baseada em strings.

*Estrutura Hier√°rquica:* Manter o estado da "Conta Atual" (account_code_current) enquanto lia as linhas filhas (transa√ß√µes).

## üîÆ Pr√≥ximos Passos (Melhorias Futuras)

*Agrupamento de Classes Raras:* Implementar a regra de neg√≥cio para transformar contas com menos de 20% da m√©dia de registros em uma categoria "OUTROS".

*Valida√ß√£o Sem√¢ntica:* Garantir rela√ß√£o 1:1 estrita entre C√≥digo da Conta e Descri√ß√£o da Conta (normalizar nomes de bancos, por exemplo).

*Testes Unit√°rios:* Criar testes automatizados para validar o regex de limpeza e o parser.